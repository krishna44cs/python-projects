{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b018285c",
   "metadata": {},
   "source": [
    "# AWS FAN OUT ARCHITECTURE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e13d560",
   "metadata": {},
   "source": [
    "SQS ROLE = cloudwatch,s3,sqs ( PERMISSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1ca0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sqs role edit in json \n",
    "{\n",
    "\t\"Version\": \"2012-10-17\",\n",
    "\t\"Statement\": [\n",
    "\t\t{\n",
    "\t\t\t\"Sid\": \"VisualEditor0\",\n",
    "\t\t\t\"Effect\": \"Allow\",\n",
    "\t\t\t\"Action\": [\n",
    "\t\t\t\t\"s3:GetObject\",\n",
    "\t\t\t\t\"s3:DeleteObject\"\n",
    "\t\t\t],\n",
    "\t\t\t\"Resource\": \"arn:aws:s3:::krishna-input/krishna/*\"\n",
    "\t\t},\n",
    "\t\t{\n",
    "\t\t\t\"Sid\": \"VisualEditor1\",\n",
    "\t\t\t\"Effect\": \"Allow\",\n",
    "\t\t\t\"Action\": \"s3:ListBucket\",\n",
    "\t\t\t\"Resource\": [\n",
    "\t\t\t\t\"arn:aws:s3:::krishna-input/krishna/*\",\n",
    "\t\t\t\t\"arn:aws:s3:::krishna-input\"\n",
    "\t\t\t]\n",
    "\t\t},\n",
    "\t\t{\n",
    "\t\t\t\"Sid\": \"VisualEditor2\",\n",
    "\t\t\t\"Effect\": \"Allow\",\n",
    "\t\t\t\"Action\": \"s3:PutObject\",\n",
    "\t\t\t\"Resource\": \"arn:aws:s3:::krishna-output/krishna/*\"\n",
    "\t\t},\n",
    "\t\t{\n",
    "\t\t\t\"Sid\": \"VisualEditor3\",\n",
    "\t\t\t\"Effect\": \"Allow\",\n",
    "\t\t\t\"Action\": \"sqs:*\",\n",
    "\t\t\t\"Resource\": \"*\"\n",
    "\t\t}\n",
    "\t]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb4a7e7",
   "metadata": {},
   "source": [
    "# 1.S3 SOURCE "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e021f9",
   "metadata": {},
   "source": [
    "In the Event notification add lambda ( as put function )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba7d7ca7",
   "metadata": {},
   "source": [
    "# 2. S3 TARGET"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd5be697",
   "metadata": {},
   "source": [
    "# 2. lambda1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "263e7380",
   "metadata": {},
   "source": [
    "SQS ROLE, ADD TRIGGER AS S3 SOURCE BUCKET (PUT OPERATION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034a3cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "##code to write in lambda \n",
    "import os\n",
    "import boto3 \n",
    "\n",
    "def lambda_handler(event, context):\n",
    "    print(event)\n",
    "    \n",
    "    s = boto3.resource('s3')\n",
    "    bucket = s.Bucket('vineet-source')\n",
    "    dest_bucket = s.Bucket('vineet-target')\n",
    "    print(dest_bucket)\n",
    "    print(bucket)\n",
    "    \n",
    "    # Replace 'YOUR_QUEUE_URL' with the actual URL of your SQS queue\n",
    "    queue_url = os.environ[\"sqs_queue_url\"]\n",
    "    print(\"queue url {}\".format(queue_url))\n",
    "    \n",
    "    # Initialize the S3 and SQS clients\n",
    "    s3 = boto3.client('s3')\n",
    "    sqs = boto3.client('sqs')\n",
    "    s3_client = boto3.client('s3')\n",
    "    \n",
    "    # Replace 'YOUR_BUCKET_NAME' and 'YOUR_FILE_KEY' with the actual S3 bucket and file key\n",
    "    bucket_name = 'vineet-target'\n",
    "    print('hi')\n",
    "    dest_key = None  # Initialize dest_key outside the loop\n",
    "    for obj in bucket.objects.filter(Prefix='images/', Delimiter='/'):\n",
    "        print('hello')\n",
    "        dest_key = obj.key\n",
    "        print(dest_key)\n",
    "        print(obj.key)\n",
    "        print('copy file ' + dest_key)\n",
    "        s.Object(dest_bucket.name, dest_key).copy_from(CopySource={'Bucket': obj.bucket_name, 'Key': obj.key})\n",
    "        print('delete file from source bucket ' + dest_key)\n",
    "        s.Object(bucket.name, obj.key).delete()\n",
    "\n",
    "    if dest_key is not None:\n",
    "        # If there was at least one object copied, continue with the rest of the logic\n",
    "        \n",
    "        try:\n",
    "            response = s3_client.list_objects_v2(Bucket=bucket_name)\n",
    "            \n",
    "            if 'Contents' in response:\n",
    "                # Sort objects by the 'LastModified' timestamp in descending order\n",
    "                sorted_objects = sorted(response['Contents'], key=lambda obj: obj['LastModified'], reverse=True)\n",
    "                \n",
    "                # Get the latest file name\n",
    "                latest_file_key = sorted_objects[0]['Key']\n",
    "                print(\"Latest file name:\", latest_file_key)\n",
    "                \n",
    "            else:\n",
    "                print(\"Bucket is empty.\")\n",
    "        except Exception as e:\n",
    "            print(\"Error:\", e)\n",
    "        \n",
    "        #file_key = dest_key  # Use dest_key instead of 'dest_key'\n",
    "         \n",
    "        # Send the file content as a message to SQS\n",
    "        print(obj.key)\n",
    "        print(dest_key)\n",
    "        sqs.send_message(\n",
    "            QueueUrl=queue_url,\n",
    "            MessageBody=\"message_sent_sqs\",\n",
    "            MessageAttributes={\n",
    "                'bucket': {'DataType': 'String', 'StringValue': bucket_name},\n",
    "                'fileKey': {'DataType': 'String', 'StringValue': obj.key}\n",
    "            }\n",
    "        )\n",
    "\n",
    "        # Return a success message if needed\n",
    "        return \"File content sent to SQS successfully.\"\n",
    "    else:\n",
    "        # Handle the scenario when no objects were copied\n",
    "        print(\"No objects to copy. Aborting operation.\")\n",
    "        return \"No objects to copy. Aborting operation.\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "359be2a6",
   "metadata": {},
   "source": [
    "# SQS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac891456",
   "metadata": {},
   "source": [
    "SQS ROLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096ce6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import boto3 \n",
    "\n",
    "def lambda_handler(event, context):\n",
    "    print(event)\n",
    "    \n",
    "    s = boto3.resource('s3')\n",
    "    bucket = s.Bucket('vineet-source')\n",
    "    dest_bucket = s.Bucket('vineet-target')\n",
    "    print(dest_bucket)\n",
    "    print(bucket)\n",
    "    \n",
    "    # Replace 'YOUR_QUEUE_URL' with the actual URL of your SQS queue\n",
    "    queue_url = os.environ[\"sqs_queue_url\"]\n",
    "    print(\"queue url {}\".format(queue_url))\n",
    "    \n",
    "    # Initialize the S3 and SQS clients\n",
    "    s3 = boto3.client('s3')\n",
    "    sqs = boto3.client('sqs')\n",
    "    s3_client = boto3.client('s3')\n",
    "    \n",
    "    # Replace 'YOUR_BUCKET_NAME' and 'YOUR_FILE_KEY' with the actual S3 bucket and file key\n",
    "    bucket_name = 'vineet-target'\n",
    "    print('hi')\n",
    "    dest_key = None  # Initialize dest_key outside the loop\n",
    "    for obj in bucket.objects.filter(Prefix='images/', Delimiter='/'):\n",
    "        print('hello')\n",
    "        dest_key = obj.key\n",
    "        print(dest_key)\n",
    "        print(obj.key)\n",
    "        print('copy file ' + dest_key)\n",
    "        s.Object(dest_bucket.name, dest_key).copy_from(CopySource={'Bucket': obj.bucket_name, 'Key': obj.key})\n",
    "        print('delete file from source bucket ' + dest_key)\n",
    "        s.Object(bucket.name, obj.key).delete()\n",
    "\n",
    "    if dest_key is not None:\n",
    "        # If there was at least one object copied, continue with the rest of the logic\n",
    "        \n",
    "        try:\n",
    "            response = s3_client.list_objects_v2(Bucket=bucket_name)\n",
    "            \n",
    "            if 'Contents' in response:\n",
    "                # Sort objects by the 'LastModified' timestamp in descending order\n",
    "                sorted_objects = sorted(response['Contents'], key=lambda obj: obj['LastModified'], reverse=True)\n",
    "                \n",
    "                # Get the latest file name\n",
    "                latest_file_key = sorted_objects[0]['Key']\n",
    "                print(\"Latest file name:\", latest_file_key)\n",
    "                \n",
    "            else:\n",
    "                print(\"Bucket is empty.\")\n",
    "        except Exception as e:\n",
    "            print(\"Error:\", e)\n",
    "        \n",
    "        #file_key = dest_key  # Use dest_key instead of 'dest_key'\n",
    "         \n",
    "        # Send the file content as a message to SQS\n",
    "        print(obj.key)\n",
    "        print(dest_key)\n",
    "        sqs.send_message(\n",
    "            QueueUrl=queue_url,\n",
    "            MessageBody=\"message_sent_sqs\",\n",
    "            MessageAttributes={\n",
    "                'bucket': {'DataType': 'String', 'StringValue': bucket_name},\n",
    "                'fileKey': {'DataType': 'String', 'StringValue': obj.key}\n",
    "            }\n",
    "        )\n",
    "\n",
    "        # Return a success message if needed\n",
    "        return \"File content sent to SQS successfully.\"\n",
    "    else:\n",
    "        # Handle the scenario when no objects were copied\n",
    "        print(\"No objects to copy. Aborting operation.\")\n",
    "        return \"No objects to copy. Aborting operation.\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6251cf4",
   "metadata": {},
   "source": [
    "# LAMBDA 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45e5f29f",
   "metadata": {},
   "source": [
    " SQS ROLE, ADD TRIGGER AS SQS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab271325",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import boto3\n",
    "\n",
    "def lambda_handler(event, context):\n",
    "    # Parse the SQS event message\n",
    "    records = event['Records']\n",
    "    for record in records:\n",
    "        # Retrieve the message attributes\n",
    "        message_attributes = record['messageAttributes']\n",
    "        bucket_name = message_attributes['bucket']['stringValue']\n",
    "        file_key = message_attributes['fileKey']['stringValue']\n",
    "        \n",
    "        # Process or use the bucket_name and file_key as needed\n",
    "        # For example, you can print them or perform some operations with them.\n",
    "        print(\"Bucket Name:\", bucket_name)\n",
    "        print(\"File Key:\", file_key)\n",
    "        destination_file_key = bucket_name + '/' + file_key\n",
    "        print(destination_file_key)\n",
    "        destination_bucket='vineet-2target'\n",
    "        s3_client = boto3.client('s3')\n",
    "        s3_client.copy_object(Bucket=destination_bucket,\n",
    "                              CopySource={'Bucket': bucket_name, 'Key': file_key},\n",
    "                              Key=destination_file_key)\n",
    "    return {\n",
    "        'statusCode': 200,\n",
    "        'body': json.dumps('Lambda function execution completed successfully!')\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78987b36",
   "metadata": {},
   "source": [
    "CREATE A S3 TARGET BUCKET (2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "349168b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
